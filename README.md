<div align="center">
  <img src="logo.png" alt="gymemu" width="512"/>

  # gymemu

  [![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
  [![Python](https://img.shields.io/badge/Python-3.11-3776AB.svg)](https://python.org)
  [![PyTorch](https://img.shields.io/badge/PyTorch-CUDA_11.8-EE4C2C.svg)](https://pytorch.org)
  [![Hugging Face](https://img.shields.io/badge/Models-Hugging_Face-FFD21E.svg)](https://huggingface.co/tsilva)

  **ğŸ® Play retro games through learned latent dynamicsâ€”no ROM required ğŸ§ **

  [How It Works](#how-it-works) Â· [Quick Start](#quick-start) Â· [Controls](#controls)
</div>

---

## Overview

Gymnasium Emulator visualizes and interacts with the latent dynamics of retro games using pre-trained deep learning models. Instead of traditional emulation, it uses a convolutional autoencoder to encode game frames into a 32-dimensional latent space and a dynamics model to predict how that state changes with each action.

The result: real-time gameplay powered entirely by neural networks.

## How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Keyboard   â”‚ â”€â”€â–¶ â”‚   Dynamics   â”‚ â”€â”€â–¶ â”‚   Decoder   â”‚ â”€â”€â–¶ Display
â”‚   Input     â”‚     â”‚    Model     â”‚     â”‚  (latentâ†’   â”‚
â”‚ (9 actions) â”‚     â”‚ (Î” latent)   â”‚     â”‚   frame)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    latent + Î”latent
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                    â”‚   Current   â”‚
                    â”‚   Latent    â”‚
                    â”‚   State     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **Autoencoder**: 3-layer convolutional network compresses 80Ã—144 grayscale frames to 32 dimensions
- **Dynamics Model**: Predicts the *change* in latent space given an action (residual connection)
- **30 FPS**: Real-time visualization through Pygame

Models are downloaded automatically from Hugging Face at runtime.

## Quick Start

**Prerequisites**: Python 3.11+, NVIDIA GPU with CUDA support

```bash
# Clone and setup
git clone https://github.com/tsilva/gymemu.git
cd gymemu

# Create environment and install dependencies
python3 -m venv .venv
source .venv/bin/activate
pip install --extra-index-url https://download.pytorch.org/whl/cu118 -e .

# Configure Hugging Face token (only for pre-trained models)
cp .env.example .env
# Edit .env and add: HF_TOKEN=your-token

# Run with pre-trained models
python main.py
```

## Training Your Own Models

You can train neural emulator models on any Hugging Face dataset with the same format:

```bash
# Train on a dataset (e.g., Super Mario Bros)
python train.py \
    --dataset tsilva/gymnasium-recorder__SuperMarioBros_Nes_v0 \
    --epochs 50 \
    --batch-size 128 \
    --latent-dim 32 \
    --image-size 80
```

This creates two model files in `./models/`:
- `{dataset}-representation.pt` (autoencoder)
- `{dataset}-dynamics.pt` (dynamics model)

### Using Trained Models

Update `main.py` to use local models:

```python
# Line 17 in main.py
use_local_models = True  # Changed from False

# Line 9 in main.py - use sanitized dataset name
ds_id = "tsilva__gymnasium-recorder__SuperMarioBros_Nes_v0"
```

Then run: `python main.py`

### Training Configuration

| Argument | Default | Description |
|----------|---------|-------------|
| `--dataset` | Required | Hugging Face dataset ID |
| `--epochs` | 50 | Training epochs per phase |
| `--batch-size` | 128 | Batch size |
| `--latent-dim` | 32 | Latent space dimensionality |
| `--image-size` | 80 | Input image size (80Ã—80) |
| `--output-dir` | ./models | Where to save models |

### Two-Phase Training

**Phase 1**: Autoencoder learns to compress game frames to latent space (L1 reconstruction loss)

**Phase 2**: Dynamics model learns to predict latent deltas given actions (MSE loss)

Validation runs every epoch for both phases, with best models saved automatically.

## Controls

| Key | Action |
|-----|--------|
| `Z` | A button |
| `X` | B button |
| `Q` | SELECT |
| `R` | START |
| `â†‘` `â†“` `â†` `â†’` | D-pad |

## Requirements

| Component | Requirement |
|-----------|-------------|
| Python | 3.11 |
| GPU | NVIDIA with CUDA 11.8+ |
| RAM | 8GB+ recommended |
| Dependencies | PyTorch, Pygame, PIL, NumPy |

## Project Structure

```
gymemu/
â”œâ”€â”€ main.py           # Neural emulator inference (real-time gameplay)
â”œâ”€â”€ train.py          # Training script for autoencoder and dynamics models
â”œâ”€â”€ start.png         # Initial game frame (Tetris title screen)
â”œâ”€â”€ pyproject.toml    # Project metadata and dependencies
â”œâ”€â”€ .env.example      # Template for Hugging Face credentials
â””â”€â”€ models/           # Trained models (created by train.py)
```

## License

[MIT](LICENSE) Â© 2025 Tiago Silva